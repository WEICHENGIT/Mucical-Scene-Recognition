{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - SD207\n",
    "\n",
    "## Groupe : WEI Chen ,  LUO Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\qda.py:6: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = np.loadtxt(\"train.txt\", dtype = \"string\")\n",
    "tr_fn = df1[:,0]\n",
    "tr_labels_name = df1[:,1]\n",
    "u,tr_labels = np.unique(tr_labels_name, return_inverse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tr_fn.shape[0]):\n",
    "    y,sr = librosa.load(tr_fn[i])\n",
    "    mfcc =librosa.feature.mfcc(y = y, n_fft = 8192,hop_length = 8192, n_mfcc = 20 )\n",
    "    if i == 0:\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        cqt = librosa.cqt(y = y, sr = sr, hop_length= 8192, fmin = 5, n_bins = 24*11, bins_per_octave= 24, real = True)\n",
    "        X_tr = np.c_[mfcc.T, mfcc_delta.T, mfcc_delta2.T, cqt.T]\n",
    "        y_tr = tr_labels[i] * np.array([1]* mfcc.shape[1])\n",
    "    else: \n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        cqt = librosa.cqt(y = y, sr = sr, hop_length= 8192, fmin = 5, n_bins = 24*11, bins_per_octave= 24, real = True)\n",
    "        tmp = np.c_[mfcc.T, mfcc_delta.T,mfcc_delta2.T, cqt.T]\n",
    "        X_tr  = np.concatenate((X_tr,tmp), axis = 0)\n",
    "        y_tr = np.concatenate((y_tr, tr_labels[i] * np.array([1]* mfcc.shape[1])), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47142L, 324L)\n",
      "(47142L,)\n"
     ]
    }
   ],
   "source": [
    "print X_tr.shape\n",
    "print y_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = np.loadtxt(\"dev.txt\", dtype = \"string\")\n",
    "tt_fn = df2[:,0]\n",
    "tt_lb = df2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290L,)\n"
     ]
    }
   ],
   "source": [
    "u,tt_labels= np.unique(tt_lb, return_inverse= True)\n",
    "print tt_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tt_fn.shape[0]):\n",
    "    y,sr = librosa.load(tt_fn[i])\n",
    "    mfcc = librosa.feature.mfcc(y = y, n_fft = 8192,hop_length = 8192, n_mfcc = 20 )\n",
    "    if i == 0:\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        cqt = librosa.cqt(y = y, sr = sr, hop_length= 8192, fmin = 5, n_bins = 24*11, bins_per_octave= 24, real = True)\n",
    "        X_tt = np.c_[mfcc.T, mfcc_delta.T,mfcc_delta2.T, cqt.T]\n",
    "        y_tt = tt_labels[i] * np.array([1]* mfcc.shape[1])\n",
    "    else: \n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        cqt = librosa.cqt(y = y, sr = sr, hop_length= 8192, fmin = 5, n_bins = 24*11, bins_per_octave= 24, real = True)\n",
    "        tmp = np.c_[mfcc.T, mfcc_delta.T,mfcc_delta2.T, cqt.T] \n",
    "        X_tt  = np.concatenate((X_tt,tmp), axis = 0)\n",
    "        y_tt = np.concatenate((y_tt, tr_labels[i] * np.array([1]* mfcc.shape[1])), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23490L, 324L)\n",
      "(23490L,)\n"
     ]
    }
   ],
   "source": [
    "print X_tt.shape\n",
    "print y_tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = np.loadtxt(\"test_files.txt\", dtype = \"string\")\n",
    "for i in range(df3.shape[0]):\n",
    "    y,sr = librosa.load(df3[i])\n",
    "    mfcc = librosa.feature.mfcc(y = y, n_fft = 8192,hop_length = 8192, n_mfcc = 20 )\n",
    "    if i == 0:\n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        cqt = librosa.cqt(y = y, sr = sr, hop_length= 8192, fmin = 5, n_bins = 24*11, bins_per_octave= 24, real = True)\n",
    "        X_v = np.c_[mfcc.T, mfcc_delta.T,mfcc_delta2.T,cqt.T]\n",
    "    else: \n",
    "        mfcc_delta = librosa.feature.delta(mfcc)\n",
    "        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "        cqt = librosa.cqt(y = y, sr = sr, hop_length= 8192, fmin = 5, n_bins = 24*11, bins_per_octave= 24, real = True)\n",
    "        tmp = np.c_[mfcc.T, mfcc_delta.T,mfcc_delta2.T,cqt.T]\n",
    "        X_v  = np.concatenate((X_v,tmp), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Vote Weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def majority_vote(y_pred, y_true, w, pas):\n",
    "    ac = 0\n",
    "    scr = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        counts = np.bincount(y_pred[i*pas:(i+1)*pas],weights = w[i*pas:(i+1)*pas])\n",
    "        scr.append(np.max(counts)/pas)\n",
    "        if np.argmax(counts) == y_true[i]:\n",
    "            ac = ac + 1\n",
    "            \n",
    "    return [ac/float(y_true.shape[0]),scr] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Store(y_pred,w,pas):\n",
    "    y_st = np.zeros((298,))\n",
    "    scr = []\n",
    "    for i in range(298):\n",
    "        counts = np.bincount(y_pred[i*pas:(i+1)*pas], weights=w[i*pas:(i+1)*pas])\n",
    "        y_st[i] = np.argmax(counts)\n",
    "        scr.append(np.max(counts)/np.sum(counts))\n",
    "    np.savetxt('y_pred.txt', y_st, fmt='%d')\n",
    "    return [y_st,scr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(np.concatenate((X_tr,X_tt),axis = 0), \n",
    "                                                     np.concatenate((y_tr,y_tt),axis  = 0), test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70632L, 324L)\n",
      "(70632L,)\n"
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate((X_tr,X_tt), axis = 0)\n",
    "y_train = np.concatenate((y_tr,y_tt), axis = 0)\n",
    "print X_train.shape\n",
    "print y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training... (PCA, MLP, bagging QDA...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(200,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=300)\n",
    "X_pca = pca.fit_transform(X_train)\n",
    "\n",
    "#clf = MLPClassifier(hidden_layer_sizes= (200,), random_state = 1, warm_start= True )\n",
    "#clf = BaggingClassifier(mlp, n_estimators= 30, max_samples=0.7, max_features= 0.7)\n",
    "#clf1.fit(X_train,y_train)\n",
    "#clf2 = MLPClassifier(hidden_layer_sizes=(190,))\n",
    "#clf.fit(X_pca,y_train) \n",
    "#print clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(180,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='adam', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False),\n",
       "         bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "         max_samples=0.7, n_estimators=20, n_jobs=True, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes= (180,), random_state = 1 )\n",
    "clf = BaggingClassifier(mlp, n_estimators= 20, max_samples=0.7, max_features= 0.5, n_jobs = True)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514313625552\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes= (200,), random_state = 1, warm_start= True )\n",
    " \n",
    "print cross_val_score(clf,X_train, y_train, cv = 3, n_jobs = 3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924137931034\n"
     ]
    }
   ],
   "source": [
    "y_pred2 = clf.predict(X_tt)\n",
    "proba = np.amax(clf.predict_proba(X_tt), axis = 1)\n",
    "print majority_vote(y_pred2,tt_labels, proba,81)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10.   8.   3.   7.   1.   5.   7.  14.   3.   7.  10.  12.   6.  14.  12.\n",
      "   5.  12.   8.   0.   8.   8.   6.   7.  12.  12.   8.   6.   8.  11.   3.\n",
      "  14.   1.  10.  12.   8.   5.   3.  14.  14.   4.   7.   0.   0.   7.   6.\n",
      "  11.  12.   6.   3.   8.  11.   6.  12.  12.   6.  10.   8.   6.   5.  11.\n",
      "   7.  12.  14.  11.   6.  14.   9.   7.   3.   4.   0.  14.  11.   7.  14.\n",
      "   6.   1.   9.   1.  10.  12.   0.   4.   6.  13.   3.  14.  13.   1.   9.\n",
      "  12.  13.  10.   6.  14.   1.  12.  10.   5.  14.   1.  13.   6.   6.   7.\n",
      "  14.   7.   7.   5.  14.   4.  12.  14.  13.   3.   0.   0.   9.   9.  10.\n",
      "  13.   3.   4.   6.   1.   1.   1.  12.   4.   5.  14.  10.   1.  10.   6.\n",
      "   6.  11.  12.  12.  14.  12.   5.  12.   8.   3.   3.   9.   7.   1.   8.\n",
      "   7.   3.   3.  13.   9.  13.  12.  12.   1.   6.   7.   4.   9.   9.  14.\n",
      "   1.   9.   5.  10.   7.   1.  13.   0.   0.  11.  14.   8.   7.  12.  12.\n",
      "   5.   6.   4.  13.   5.   6.   4.  14.   7.   9.  14.   7.   4.  11.   9.\n",
      "   3.   9.   2.   8.   0.   1.  10.  14.   3.  11.   0.   4.  14.  14.   4.\n",
      "   9.   6.   6.   7.  11.  13.   6.  14.   6.   1.   6.   7.   3.  13.   9.\n",
      "  12.  13.   1.   2.   4.   9.  11.  12.  10.  12.   7.   8.   5.   4.   7.\n",
      "   8.   7.   3.  11.   7.   5.   4.   7.  11.   1.  13.  13.  14.   6.  10.\n",
      "   5.  14.   5.   1.   8.  10.   7.  12.   7.   8.  12.   7.   0.  14.   4.\n",
      "  10.   3.   6.   1.   4.  11.   6.   1.   8.   8.   9.   5.   3.  14.   6.\n",
      "   6.  10.  14.  13.   0.   9.  10.   0.   9.   8.   9.   5.  12.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred3 = clf.predict(X_v)\n",
    "proba3 = np.amax(clf.predict_proba(X_v), axis = 1)\n",
    "print Store(y_pred3,proba3,81)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
